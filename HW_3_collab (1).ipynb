{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwYPi_tZH08B"
   },
   "source": [
    "# Домашнее задание 3: Natural Language Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Viukgu3RHt_P"
   },
   "outputs": [],
   "source": [
    "# импортируем библиотеки\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xZxOivgTHt8e"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/mcdm/CommitmentBank/master/CommitmentBank-items.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-nLtDzRJt7n"
   },
   "source": [
    "Давайте создадим дополнительную колонку под названием Relation и будем записывать туда entailment, если значение комитмента находится в интервале [1,3]. Если значение комитмента находится в интервале (-1;1), то в колонку Relation записываем neutral. Если же значение комитмента находится в интервале [-3,-1], то в колонку Relation записываем contradiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "y7WmJ9-VHtj4"
   },
   "outputs": [],
   "source": [
    "def determine_relation(mean_value):\n",
    "    if 1 <= mean_value <= 3:\n",
    "        return 'entailment'\n",
    "    elif -1 < mean_value < 1:\n",
    "        return 'neutral'\n",
    "    elif -3 <= mean_value <= -1:\n",
    "        return 'contradiction'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ojpm4Hp1Htb6"
   },
   "outputs": [],
   "source": [
    "df['Relation'] = df['Mean'].apply(determine_relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPaiZOh5KHHU"
   },
   "source": [
    "После того как мы заполнили колонку Relation, давайте создадим колонку label. Если в колонке Relation строка равна entailment, то запишем 0 в колонку label. Если же равна neutral, то запишем 1 в колонку label. Если contradiction, то запишем 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "j9YWEoO5KJzD",
    "outputId": "419dd87f-2ed3-425c-96f0-fbea10d05c0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uID</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Context</th>\n",
       "      <th>Target</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>ModalType</th>\n",
       "      <th>MatTense</th>\n",
       "      <th>MatSubjLemma</th>\n",
       "      <th>...</th>\n",
       "      <th>Embedding.1</th>\n",
       "      <th>genre</th>\n",
       "      <th>factive</th>\n",
       "      <th>mean.noTarget</th>\n",
       "      <th>sd.noTarget</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>Reponses</th>\n",
       "      <th>Relation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BNC-1</td>\n",
       "      <td>admit</td>\n",
       "      <td>conditional</td>\n",
       "      <td>Polly had to think quickly.</td>\n",
       "      <td>They were still close enough to shore for him ...</td>\n",
       "      <td>Polly was not an experienced ocean sailor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>future</td>\n",
       "      <td>she</td>\n",
       "      <td>...</td>\n",
       "      <td>conditional</td>\n",
       "      <td>BNC</td>\n",
       "      <td>no</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>1.269296</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>2, 3, 3, 1, 3, 1, 2, 1, 2</td>\n",
       "      <td>entailment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BNC-1002</td>\n",
       "      <td>say</td>\n",
       "      <td>modal</td>\n",
       "      <td>Nevertheless, life went on as it always does. ...</td>\n",
       "      <td>Indeed it could be said that they had prospered.</td>\n",
       "      <td>the Kiwi Keith and the Mackenzie houses had pr...</td>\n",
       "      <td>CI</td>\n",
       "      <td>present</td>\n",
       "      <td>it</td>\n",
       "      <td>...</td>\n",
       "      <td>modal</td>\n",
       "      <td>BNC</td>\n",
       "      <td>no</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.873796</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.834523</td>\n",
       "      <td>2, 1, 3, 1, 2, 2, 3, 1</td>\n",
       "      <td>entailment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BNC-1003</td>\n",
       "      <td>say</td>\n",
       "      <td>modal</td>\n",
       "      <td>He patted her hand. If he had chosen to, Thoma...</td>\n",
       "      <td>He might have said to her that some time in th...</td>\n",
       "      <td>some time in the middle of the nineteenth cent...</td>\n",
       "      <td>AB</td>\n",
       "      <td>present</td>\n",
       "      <td>he</td>\n",
       "      <td>...</td>\n",
       "      <td>modal</td>\n",
       "      <td>BNC</td>\n",
       "      <td>no</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.462910</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>2, 0, 1, 0, 0, 3, -1, 0, 1, 0, 0, 2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BNC-1005</td>\n",
       "      <td>say</td>\n",
       "      <td>modal</td>\n",
       "      <td>She could see his distorted image in the slant...</td>\n",
       "      <td>Of course she could say it was for the childre...</td>\n",
       "      <td>it was for the children</td>\n",
       "      <td>AB</td>\n",
       "      <td>future</td>\n",
       "      <td>she</td>\n",
       "      <td>...</td>\n",
       "      <td>modal</td>\n",
       "      <td>BNC</td>\n",
       "      <td>no</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.120065</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.991031</td>\n",
       "      <td>2, 1, 0, 1, -1, 1, 1, 2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BNC-1006</td>\n",
       "      <td>say</td>\n",
       "      <td>modal</td>\n",
       "      <td>She glanced around the room, laying her hot fl...</td>\n",
       "      <td>Robyn swallowed and took a deep breath trying ...</td>\n",
       "      <td>it was all right</td>\n",
       "      <td>AB</td>\n",
       "      <td>future</td>\n",
       "      <td>she</td>\n",
       "      <td>...</td>\n",
       "      <td>modal</td>\n",
       "      <td>BNC</td>\n",
       "      <td>no</td>\n",
       "      <td>-1.090909</td>\n",
       "      <td>1.044466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.309401</td>\n",
       "      <td>3, 1, -2, -3, -3, 3, 2, 1, -1, -1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>1196</td>\n",
       "      <td>WSJ-95</td>\n",
       "      <td>feel</td>\n",
       "      <td>negation</td>\n",
       "      <td>Across the board, these consumers value qualit...</td>\n",
       "      <td>Twenty percent don't even feel they are financ...</td>\n",
       "      <td>they are financially well off</td>\n",
       "      <td>NaN</td>\n",
       "      <td>present</td>\n",
       "      <td>twenty percent</td>\n",
       "      <td>...</td>\n",
       "      <td>negation</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>no</td>\n",
       "      <td>-1.750000</td>\n",
       "      <td>1.035098</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.371708</td>\n",
       "      <td>-2, 3, -3, -3, -2, -3, -3, 2, -3, -1, 3, -3, 0...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>1197</td>\n",
       "      <td>WSJ-96</td>\n",
       "      <td>mean</td>\n",
       "      <td>negation</td>\n",
       "      <td>The Fed has assumed a similar responsibility i...</td>\n",
       "      <td>This does not mean that the Federal Reserve do...</td>\n",
       "      <td>the Federal Reserve does not already play an i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>present</td>\n",
       "      <td>this</td>\n",
       "      <td>...</td>\n",
       "      <td>negation</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>no</td>\n",
       "      <td>-0.722222</td>\n",
       "      <td>1.964555</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2.028957</td>\n",
       "      <td>2, -2, 3, 0, 2, 1, 2, -2, 2, 1, -1, 0, -2, -3,...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>1198</td>\n",
       "      <td>WSJ-97</td>\n",
       "      <td>expect</td>\n",
       "      <td>modal</td>\n",
       "      <td>Under the Racketeer Influenced and Corrupt Org...</td>\n",
       "      <td>In a letter, prosecutors told Mr. Antar's lawy...</td>\n",
       "      <td>any fees collected from Mr. Antar may be seized</td>\n",
       "      <td>AB</td>\n",
       "      <td>present</td>\n",
       "      <td>they</td>\n",
       "      <td>...</td>\n",
       "      <td>modal</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>no</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.264911</td>\n",
       "      <td>2.058824</td>\n",
       "      <td>1.477777</td>\n",
       "      <td>1, 3, -3, 3, 3, 3, 2, 2, 1, 2, 2, 3, 2, 2, 3, ...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>1199</td>\n",
       "      <td>WSJ-98</td>\n",
       "      <td>believe</td>\n",
       "      <td>negation</td>\n",
       "      <td>Talks between the two sides could unravel, of ...</td>\n",
       "      <td>And although Warner has said it wanted the pro...</td>\n",
       "      <td>the relationship could be repaired after the a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>present</td>\n",
       "      <td>they</td>\n",
       "      <td>...</td>\n",
       "      <td>negation</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>no</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>1.378954</td>\n",
       "      <td>-1.733333</td>\n",
       "      <td>1.751190</td>\n",
       "      <td>-1, -3, -3, -1, -2, 1, -3, -3, -3, -3, 2, -2, ...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>1200</td>\n",
       "      <td>WSJ-99</td>\n",
       "      <td>think</td>\n",
       "      <td>negation</td>\n",
       "      <td>``I don't think the market is going through an...</td>\n",
       "      <td>Mr. Cooperman sees this as a good time to pick...</td>\n",
       "      <td>there's any need to rush</td>\n",
       "      <td>NaN</td>\n",
       "      <td>present</td>\n",
       "      <td>he</td>\n",
       "      <td>...</td>\n",
       "      <td>negation</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>no</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.632993</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>2.030717</td>\n",
       "      <td>-1, 2, -2, 3, 2, -1, 1, 0, 3, -3, 1, -3, 2, 1, 2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0       uID     Verb    Embedding  \\\n",
       "0              1     BNC-1    admit  conditional   \n",
       "1              2  BNC-1002      say        modal   \n",
       "2              3  BNC-1003      say        modal   \n",
       "3              4  BNC-1005      say        modal   \n",
       "4              5  BNC-1006      say        modal   \n",
       "...          ...       ...      ...          ...   \n",
       "1195        1196    WSJ-95     feel     negation   \n",
       "1196        1197    WSJ-96     mean     negation   \n",
       "1197        1198    WSJ-97   expect        modal   \n",
       "1198        1199    WSJ-98  believe     negation   \n",
       "1199        1200    WSJ-99    think     negation   \n",
       "\n",
       "                                                Context  \\\n",
       "0                           Polly had to think quickly.   \n",
       "1     Nevertheless, life went on as it always does. ...   \n",
       "2     He patted her hand. If he had chosen to, Thoma...   \n",
       "3     She could see his distorted image in the slant...   \n",
       "4     She glanced around the room, laying her hot fl...   \n",
       "...                                                 ...   \n",
       "1195  Across the board, these consumers value qualit...   \n",
       "1196  The Fed has assumed a similar responsibility i...   \n",
       "1197  Under the Racketeer Influenced and Corrupt Org...   \n",
       "1198  Talks between the two sides could unravel, of ...   \n",
       "1199  ``I don't think the market is going through an...   \n",
       "\n",
       "                                                 Target  \\\n",
       "0     They were still close enough to shore for him ...   \n",
       "1      Indeed it could be said that they had prospered.   \n",
       "2     He might have said to her that some time in th...   \n",
       "3     Of course she could say it was for the childre...   \n",
       "4     Robyn swallowed and took a deep breath trying ...   \n",
       "...                                                 ...   \n",
       "1195  Twenty percent don't even feel they are financ...   \n",
       "1196  This does not mean that the Federal Reserve do...   \n",
       "1197  In a letter, prosecutors told Mr. Antar's lawy...   \n",
       "1198  And although Warner has said it wanted the pro...   \n",
       "1199  Mr. Cooperman sees this as a good time to pick...   \n",
       "\n",
       "                                                 Prompt ModalType MatTense  \\\n",
       "0             Polly was not an experienced ocean sailor       NaN   future   \n",
       "1     the Kiwi Keith and the Mackenzie houses had pr...        CI  present   \n",
       "2     some time in the middle of the nineteenth cent...        AB  present   \n",
       "3                               it was for the children        AB   future   \n",
       "4                                      it was all right        AB   future   \n",
       "...                                                 ...       ...      ...   \n",
       "1195                      they are financially well off       NaN  present   \n",
       "1196  the Federal Reserve does not already play an i...       NaN  present   \n",
       "1197    any fees collected from Mr. Antar may be seized        AB  present   \n",
       "1198  the relationship could be repaired after the a...       NaN  present   \n",
       "1199                           there's any need to rush       NaN  present   \n",
       "\n",
       "        MatSubjLemma  ...  Embedding.1 genre factive mean.noTarget  \\\n",
       "0                she  ...  conditional   BNC      no     -0.111111   \n",
       "1                 it  ...        modal   BNC      no      1.200000   \n",
       "2                 he  ...        modal   BNC      no     -0.250000   \n",
       "3                she  ...        modal   BNC      no      0.636364   \n",
       "4                she  ...        modal   BNC      no     -1.090909   \n",
       "...              ...  ...          ...   ...     ...           ...   \n",
       "1195  twenty percent  ...     negation   WSJ      no     -1.750000   \n",
       "1196            this  ...     negation   WSJ      no     -0.722222   \n",
       "1197            they  ...        modal   WSJ      no      1.600000   \n",
       "1198            they  ...     negation   WSJ      no      1.083333   \n",
       "1199              he  ...     negation   WSJ      no     -1.000000   \n",
       "\n",
       "     sd.noTarget      Mean        SD  \\\n",
       "0       1.269296  2.000000  0.866025   \n",
       "1       1.873796  1.875000  0.834523   \n",
       "2       0.462910  0.666667  1.154701   \n",
       "3       1.120065  0.875000  0.991031   \n",
       "4       1.044466  0.000000  2.309401   \n",
       "...          ...       ...       ...   \n",
       "1195    1.035098 -1.000000  2.371708   \n",
       "1196    1.964555  0.125000  2.028957   \n",
       "1197    1.264911  2.058824  1.477777   \n",
       "1198    1.378954 -1.733333  1.751190   \n",
       "1199    1.632993  0.466667  2.030717   \n",
       "\n",
       "                                               Reponses       Relation label  \n",
       "0                             2, 3, 3, 1, 3, 1, 2, 1, 2     entailment     0  \n",
       "1                                2, 1, 3, 1, 2, 2, 3, 1     entailment     0  \n",
       "2                   2, 0, 1, 0, 0, 3, -1, 0, 1, 0, 0, 2        neutral     1  \n",
       "3                               2, 1, 0, 1, -1, 1, 1, 2        neutral     1  \n",
       "4                     3, 1, -2, -3, -3, 3, 2, 1, -1, -1        neutral     1  \n",
       "...                                                 ...            ...   ...  \n",
       "1195  -2, 3, -3, -3, -2, -3, -3, 2, -3, -1, 3, -3, 0...  contradiction     2  \n",
       "1196  2, -2, 3, 0, 2, 1, 2, -2, 2, 1, -1, 0, -2, -3,...        neutral     1  \n",
       "1197  1, 3, -3, 3, 3, 3, 2, 2, 1, 2, 2, 3, 2, 2, 3, ...     entailment     0  \n",
       "1198  -1, -3, -3, -1, -2, 1, -3, -3, -3, -3, 2, -2, ...  contradiction     2  \n",
       "1199   -1, 2, -2, 3, 2, -1, 1, 0, 3, -3, 1, -3, 2, 1, 2        neutral     1  \n",
       "\n",
       "[1200 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание колонки \"label\" на основе значений в колонке \"Relation\"\n",
    "df['label'] = df['Relation'].map({'entailment': 0, 'neutral': 1, 'contradiction': 2})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S46c6X9uKPaX"
   },
   "source": [
    "Разобьем наш датасет на два набора: набор для изучения(70-80% исходного набора данных) и тестовы набор(20-30% исходного набора данных)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "e15blVhNKRJL"
   },
   "outputs": [],
   "source": [
    "from sklearn. model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size= 0.2 , random_state= 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9s9q23XGl9-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from nlp import tools\n",
    "import nlp.tools.tokenization\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uxfneFvrHVCL"
   },
   "outputs": [],
   "source": [
    "gs_folder_bert = \"gs://cloud-tpu-checkpoints/bert/keras_bert/uncased_L-12_H-768_A-12\"\n",
    "tokenizer = tools.tokenization.FullTokenizer(vocab_file=os.path.join(gs_folder_bert, \"vocab.txt\"),\n",
    "     do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iJdzsc5mHZKW"
   },
   "outputs": [],
   "source": [
    "def encode_sentence(s, tokenizer):\n",
    "   tokens = list(tokenizer.tokenize(s))\n",
    "   tokens.append('[SEP]')\n",
    "   return tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Czp11fd7KcBL"
   },
   "outputs": [],
   "source": [
    "def bert_input_encoder(train, tokenizer):\n",
    "  premises = tf.ragged.constant([encode_sentence(s, tokenizer) for s in np.array(train['Target'])])\n",
    "  hypotheses = tf.ragged.constant([encode_sentence(s, tokenizer) for s in np.array(train['Prompt'])])\n",
    "\n",
    "  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])] * premises.shape[0]\n",
    "\n",
    "  input_word_ids = tf.concat([cls, premises, hypotheses], axis=-1)\n",
    "\n",
    "  input_mask = tf.ones_like(input_word_ids).to_tensor()\n",
    "\n",
    "  segment_cls = tf.zeros_like(cls)\n",
    "  segment_s1 = tf.zeros_like(premises)\n",
    "  segment_s2 = tf.ones_like(hypotheses)\n",
    "  input_segment_ids = tf.concat([segment_cls, segment_s1, segment_s2], axis=-1).to_tensor()\n",
    "\n",
    "  inputs_dic = {\n",
    "    'input_word_ids': input_word_ids.to_tensor(),\n",
    "    'input_mask': input_mask,\n",
    "    'input_segment_ids': input_segment_ids\n",
    "  }\n",
    "\n",
    "  return inputs_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "akufYCNaLTT7",
    "outputId": "95c1137a-6f96-4d06-cefc-2fb45f798982"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_word_ids': <tf.Tensor: shape=(960, 123), dtype=int32, numpy=\n",
       " array([[ 101, 1045, 2123, ...,    0,    0,    0],\n",
       "        [ 101, 1998, 1045, ...,    0,    0,    0],\n",
       "        [ 101, 2065, 2012, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 1045, 2123, ...,    0,    0,    0],\n",
       "        [ 101, 2014, 2227, ...,    0,    0,    0],\n",
       "        [ 101, 1045, 2123, ...,    0,    0,    0]], dtype=int32)>,\n",
       " 'input_mask': <tf.Tensor: shape=(960, 123), dtype=int32, numpy=\n",
       " array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>,\n",
       " 'input_segment_ids': <tf.Tensor: shape=(960, 123), dtype=int32, numpy=\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input = bert_input_encoder(train, tokenizer)\n",
    "\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "vxV2tQ0PL2Tz"
   },
   "outputs": [],
   "source": [
    "def model_builder():\n",
    "  max_seq_length = 123\n",
    "\n",
    "  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "  input_segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_segment_ids\")\n",
    "\n",
    "  bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=True)\n",
    "\n",
    "  pooled_output, _ = bert_layer([input_word_ids, input_mask, input_segment_ids])\n",
    "\n",
    "  output_class = tf.keras.layers.Dense(units=3, activation='softmax')(pooled_output)\n",
    "\n",
    "  model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_segment_ids], outputs=output_class)\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(lr=1e-5)\n",
    "  model.compile(optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3wGIZpQMDdH",
    "outputId": "d37723d7-cb1a-4059-f550-6c662f2084b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer  [(None, 123)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_mask (InputLayer)     [(None, 123)]                0         []                            \n",
      "                                                                                                  \n",
      " input_segment_ids (InputLa  [(None, 123)]                0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)    [(None, 768),                1094822   ['input_word_ids[0][0]',      \n",
      "                              (None, 123, 768)]           41         'input_mask[0][0]',          \n",
      "                                                                     'input_segment_ids[0][0]']   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 3)                    2307      ['keras_layer[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109484548 (417.65 MB)\n",
      "Trainable params: 109484547 (417.65 MB)\n",
      "Non-trainable params: 1 (1.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_builder()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "GD67ZNEGMJnk"
   },
   "outputs": [],
   "source": [
    "logger = tf.keras.callbacks.TensorBoard(log_dir='/content/drive/My Drive/Collab Notebooks/first_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRIYt3apNB35",
    "outputId": "0cd580f4-0444-4bac-f64c-475440daedd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_input,\n",
    "    train.label.values,\n",
    "    epochs = 2,\n",
    "    verbose = 1,\n",
    "    batch_size = 64,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
